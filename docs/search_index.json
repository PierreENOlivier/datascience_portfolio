[["index.html", "Data Science Portfolio About Me Who I am My journey in Data Science", " Data Science Portfolio Dr. Pierre Olivier 2022-11-11 About Me Who I am This is an R Markdown format used for publishing markdown documents to GitHub. When you click the Knit button all R code chunks are run and a markdown file (.md) suitable for publishing to GitHub is generated. My journey in Data Science "],["projects-in-this-portfolio.html", "Projects in this portfolio Project 1 - Analysis of stock market data and construction of custom stock indexes Project 2 - How to build simpler network models using unsupervised machine learning File structure of projects", " Projects in this portfolio Here I will provide a short description of each project included in this portfolio. Project 1 - Analysis of stock market data and construction of custom stock indexes In this short project I extract historic stock price data, build fictional indexes, and play around with time series. Project 2 - How to build simpler network models using unsupervised machine learning This more consequent project combines network analysis and machine learning to simplify a complex network. File structure of projects Each project has been built under a common structure illustrated below. Files associated to a specific project were identified by an ID at the start of the file name. Within a project, each file is organized along the data pipeline. File structure of the portfolio "],["analysis-of-stock-market-data-and-construction-of-stock-index.html", "Part 1 Analysis of stock market data and construction of stock index 1.1 Description 1.2 Goal 1.3 Main tasks", " Part 1 Analysis of stock market data and construction of stock index 1.1 Description In this short project I want to explore a type of data I am not familiar with (i.e. stock data) and apply a set of techniques I have experience with (i.e. statistics and time series analysis). I will extract stock prices for the major computer manufacturing companies, build a fictional stock index, and analyze the fluctuations of prices over time. The project relies on R libraries to extract stock data from databases. I then, either use functions from existing packages, or build my own package, to analyze stock data and build a custom stock index. 1.2 Goal Analyze the effect of price fluctuations on different types of indexes, and process a market split. To do so, I ascribe constant arbitrary share amounts for each index component (see raw data) and use historic data to follow fluctuations in the market price. 1.3 Main tasks Download and analyze stock prices for selected components Build custom indexes Build a package/library of custom R functions Analyze market split "],["data-preprocessing.html", "Part 2 Data preprocessing 2.1 Setup project and load dependencies 2.2 Download price data from databases", " Part 2 Data preprocessing Tasks - [ ] Download daily close (unadjusted) prices for selected components - [ ] Check for missing values and replace missing values - [ ] Save the extracted data - [ ] Plot the time series 2.1 Setup project and load dependencies # install.packages(&#39;quantmod&#39;) if(!require(&quot;indexanalysis&quot;, quietly = TRUE)){ setwd(package_dir); devtools::install(&quot;indexanalysis&quot;) library(indexanalysis) }else{library(indexanalysis) ; print(&quot;loaded&quot;)} library(tidyverse) library(rlang) library(roxygen2) library(magrittr) library(glue) library(tsibble) library(quantmod) library(zoo) library(ggplot2) library(scales) library(purrr) library(furrr) library(lubridate) library(readr) The package indexanalysis contains functions that I built to simplify this analysis. 2.2 Download price data from databases 2.2.1 Read stock component parameters I selected 6 manufacturers: Apple, HP, Lenovo, Dell, Acer, and Asus. I inserted basic metadata on each component in a CSV file available in the raw data folder. index_parameters &lt;- read.csv(file.path(raw_data_dir, raw_data, &quot;notebook_index_parameters.csv&quot;), header = T, sep = &quot;,&quot;) 2.2.2 Get daily close prices from remote sources I picked an arbitrary period of historic data to carry out the analysis. symbols &lt;- index_parameters$Symbol start_date = zoo::as.Date(&quot;2021-01-01&quot;) end_date = zoo::as.Date(&quot;2021-04-01&quot;)-1 2.2.2.1 Download data for each component and prepare a tibble all_price = c(&quot;Open&quot;, &quot;Close&quot;, &quot;High&quot;, &quot;Low&quot;, &quot;Volume&quot;, &quot;Adjusted&quot;) # keep_price = c(&quot;Close&quot;) keep_price = all_price plan(multisession, workers = length(symbols)) # Fetch, filter, and format tables corresponding to each symbol prices_ts &lt;- symbols %&gt;% future_map_dfr(~indexanalysis::xts_finance_to_tibble(symbol = .x, from = start_date, to = (end_date+1) )) #&gt; Registered S3 method overwritten by &#39;quantmod&#39;: #&gt; method from #&gt; as.zoo.data.frame zoo #&gt; Registered S3 method overwritten by &#39;quantmod&#39;: #&gt; method from #&gt; as.zoo.data.frame zoo #&gt; Registered S3 method overwritten by &#39;quantmod&#39;: #&gt; method from #&gt; as.zoo.data.frame zoo #&gt; Registered S3 method overwritten by &#39;quantmod&#39;: #&gt; method from #&gt; as.zoo.data.frame zoo #&gt; Registered S3 method overwritten by &#39;quantmod&#39;: #&gt; method from #&gt; as.zoo.data.frame zoo #&gt; Registered S3 method overwritten by &#39;quantmod&#39;: #&gt; method from #&gt; as.zoo.data.frame zoo xts_finance_to_tibble fetch the data and return the time series in a tidy format. 2.2.3 Preprocess data: remove complete NAs and impute LOCF To be able to compete the index, we need complete data for each selected components (i.e. for each time step in the time series, each component takes a value). The table contains 1 row per component per time step. It does not allow us to see if some time steps (or dates) are missing for a component. We need to add the gaps to the time series and fill them. checkpoint(prices_ts) checkpoint(prices_ts, T) prices_ts %&gt;% as_tsibble(index = &quot;Date&quot;, key = &quot;Key&quot;) %&gt;% group_by_key() %&gt;% fill_gaps(.full = TRUE, .start = start_date, .end = end_date) %&gt;% pivot_longer(cols = all_of(keep_price), names_to = &quot;price&quot;, values_to = &quot;value&quot;) %&gt;% mutate(isna = is.na(value)) %&gt;% arrange(Date, price) %&gt;% unite(&quot;Component_Price&quot;, all_of(c(&quot;Key&quot;, &quot;price&quot;) ) , sep = &quot; &quot;) %&gt;% ggplot(aes(x = Date, y = Component_Price, fill = isna ))+ geom_raster()+ scale_fill_manual(name = &quot;&quot;, values = c(&quot;steelblue&quot;, &quot;tomato3&quot;), labels = c(&quot;Present&quot;, &quot;Missing&quot;))+ labs(x = &quot;Time&quot;, y = &quot;Component price&quot;) Some dates are periodically missing: most likely, non-business days and holidays. However, the missing values are not equally distributed across components (e.g., Asus, with symbol 2357.TW, is missing some data in February). We need to remove those periodic missing values and replace or remove the non-complete cases. I will here filter out: - the dates for which none of the components contain data, - carry forward the last observation (i.e. LOCF) to fill the gaps. For close and open prices, another way would be to take the previous closing price for the next opening price. ## Calculate how many components contain NAs per date prices_ts &lt;- prices_ts %&gt;% as_tibble%&gt;% select(-c(all_price[!(all_price %in% keep_price)] )) %&gt;% indexanalysis::pivot_prices_wider(nameS = &quot;Key&quot;, keep_price)%&gt;% rowwise() %&gt;% mutate(NAs = sum(is.na(c_across(!Date)) ) )%&gt;% ungroup # LOCF prices_ts &lt;- prices_ts %&gt;% # if n components x 6 prices contains NA, then no data for that day: skip the day filter(NAs &lt; length(symbols) * length(keep_price) ) %&gt;% arrange(Date) %&gt;% # For other days, LOCF tidyr::fill(contains(keep_price), .direction = &quot;down&quot;) %&gt;% select(-NAs) # Pivot longer prices_ts &lt;- prices_ts %&gt;% indexanalysis::pivot_prices_longer(symbols = symbols, separate = T)%&gt;% as_tsibble(., index = Date, key = c(&quot;Symbol&quot;, &quot;Price.Type&quot; )) 2.2.4 Save as .csv prices_ts_close &lt;- prices_ts %&gt;% as_tibble%&gt;% filter(Price.Type == &quot;Close&quot;)%&gt;% indexanalysis::pivot_prices_wider(nameS = c(&quot;Symbol&quot;, &quot;Price.Type&quot;), valueS = &quot;Price&quot;) readr::write_csv(prices_ts_close, file = file.path(clean_data_dir, project_dir, &quot;prices_ts.csv&quot; ) ) readr::write_csv(prices_ts, file = file.path(clean_data_dir, project_dir, &quot;prices_ts_all.csv&quot; ) ) "],["intro-foodweb.html", "Part 3 Introduction to networks and food webs 3.1 What are networks? 3.2 How to analyse network data", " Part 3 Introduction to networks and food webs You might remember from high school hearing about the food chain: that herbivores eat plants, carnivores eat those herbivores, and so on in a successive chain of food relationships. Relationships can be represented as data and analysed using algorithms. The food web is an extension of this concept. Because there exists many species of plants, herbivores, and carnivores in an ecosystem, there exists many interconnected food chains. The food web represents those interconnected food chains at the scale of an ecosystem and it can be mapped as a network of interactions between species. Ecological networks, such as food webs, can be represented in mathematics as a matrix, converted to a graph, and analysed using algorithms developed for network and graph theories. We can imagine food webs as social media networks, but instead of representing relationships between friends, we have relationships between enemies. The first representation of a food web (Camerano, 1880) 3.1 What are networks? Networks are graphical objects that represents entities (e.g. people) as nodes, and the connections between these nodes as edges (or links). Similarly, pairwise relationships in biological and ecological systems can be represented as nodes and links: - the nodes of the network represent ‘species’, - the links represent ‘relationships’ between those species. In food webs, the links represents ‘who eats whom’ and points to the predator. In the illustration below, each node (or species) is represented by a circle at the exception of the top predator—the Atlantic cod, Gadus morhua; each link is represented by an arrow pointing from the prey to the predator. Graphical representation of a food web 3.2 How to analyse network data We can analyse networks according to two schools: topological analysis and flow analysis. Topological analysis focuses on the structure of the network: - which are the nodes, - which other nodes are they connected to, - on average, how many relationships are represented in the network, - how are those relationships distributed across nodes, - are there any social subgroups signaling communities, - … For a longer intro to food webs and why we study food webs, you can read the summary of my doctoral thesis. In the next section, we will build network graphs from their matrix forms, analyse them, and use methods from statistics and machine learning to perform various data science tasks. Objective: We want to simplify a network by identifying nodes sharing similar characteristics. Solution: We can classify the nodes into subgroups. Subgroups are clusters of nodes with similar characteristics (e.g. they belong to the same taxonomy, or they eat similar food). However, we do not know beforehand what the subgroups will be. "],["data-preprocessing-1.html", "Part 4 Data preprocessing 4.1 Load dependencies 4.2 Data importation 4.3 Data cleaning and augmentation 4.4 List of interactions: pairwise list 4.5 ", " Part 4 Data preprocessing We will use the food web network compiled by Planque et al. (2014) which is available from the repository ‘Ecological Archives’ (ID E095-124). N.B. If needed, the dataset can be retrieved from: the Journal “Ecology”, published in Year “2014”, by the First author “Planque”, as a Data Paper (“Yes”). 4.1 Load dependencies # rm(list = ls()) library(tidyverse) library(magrittr) old_opts &lt;- options() # preserve current preferences for after we exist the function options(box.path = c(&quot;./scripts&quot;, &quot;../scripts&quot;, &quot;./scripts/box&quot;, &quot;../scripts/box&quot;) ) Load modules box::use(box/modify_strings[locate_pattern, replace_pattern]) # box::use(box/refresh_box[refresh]) # refresh(&quot;box/modify_strings&quot;) 4.2 Data importation The dataset is provided as tables formatted inside text files. 4.2.1 Import species list species_list &lt;- read.delim(&quot;raw_data/Barents_Sea/SpeciesList_2015.txt&quot;, header = TRUE) sp_save &lt;- species_list # keep original copy head(species_list) #&gt; TROPHOSPECIES ABBREVIATION PHYLUM_SUBPYLUM CLASS #&gt; 1 DETRITUS DET_IND Detritus Detritus #&gt; 2 AUTOTHROPH_FLAGELLAT AUT_FLA Autotroph flagellates Autotroph flagellates #&gt; 3 BACTERIA_INDET BAC_IND Picoplankton Picoplankton #&gt; 4 DIATOM DIATOM Microplankton Microplankton #&gt; 5 HETEROTROPH_FLAGELLAT HET_FLA Heterotroph flagellates Heterotroph flagellates #&gt; 6 ICE_ALGAE ICE_ALG Ice algae Ice algae #&gt; ORDER FAMILY GROUP #&gt; 1 Detritus Detritus 1_Plankton #&gt; 2 Autotroph flagellates Autotroph flagellates 1_Plankton #&gt; 3 Picoplankton Picoplankton 1_Plankton #&gt; 4 Microplankton Microplankton 1_Plankton #&gt; 5 Heterotroph flagellates Heterotroph flagellates 1_Plankton #&gt; 6 Ice algae Ice algae 1_Plankton The list of species is provide as a table that contains the species names along with an abbreviation and the taxonomy (i.e. classification of each organism). 4.2.2 Import interactions list pairwise_list &lt;- read.delim(&quot;raw_data/Barents_Sea/PairwiseList_2015.txt&quot;, header = TRUE) pw_save &lt;- species_list # keep original copy head(pairwise_list) #&gt; PWKEY PREDATOR PREY CODE #&gt; 1 ACA_SPP-ACA_SPP ACARTIA_SPP ACARTIA_SPP 2 #&gt; 2 ACA_SPP-AUT_FLA ACARTIA_SPP AUTOTHROPH_FLAGELLAT 1 #&gt; 3 ACA_SPP-DIATOM ACARTIA_SPP DIATOM 1 #&gt; 4 ACA_SPP-HET_FLA ACARTIA_SPP HETEROTROPH_FLAGELLAT 1 #&gt; 5 ACA_SPP-MIX_FLA ACARTIA_SPP MIXOTROPH_FLAGELLATES 4 #&gt; 6 ACA_SPP-PROZOO ACARTIA_SPP PROTOZOOPLANKTON 1 The list of trophic interactions (a.k.a. relationships of ‘who eats and whom’) is provided as a pairwise list. The first column contains an identifier. The consecutive columns PREDATOR and PREY contains the species names of the predator and prey, respectively. The rows contain the relationships between a predator and a prey. 4.2.3 Import literature references references &lt;- read.delim(&quot;raw_data/Barents_Sea/References_2015.txt&quot;) pairwise_to_references &lt;- read.delim(&quot;raw_data/Barents_Sea/Pairwise2References_2015.txt&quot;) Both ‘references’ and ‘pairwise_to_references’ tables contain metadata about the interactions. 4.3 Data cleaning and augmentation 4.3.1 Species list 4.3.1.1 Correct mispelling and non-letter characters Correct mispelling in column names: species_list %&lt;&gt;% dplyr::rename(., PHYLUM_SUBPHYLUM = PHYLUM_SUBPYLUM) Correct mispelling in species name Identify patterns using regular expressions while excluding the “_” in the names Check what patterns need replacing Replace the patterns # Helper function to apply to each column box::use(box/modify_strings[locate_pattern]) strings_to_correct &lt;- locate_pattern(species_list, &quot;[^0-9a-zA-Z_]&quot;) #&gt; NA rows contain the pattern: [^0-9a-zA-Z_] #&gt; Column: 1 #&gt; Column: 2 #&gt; Column: 3 #&gt; Column: 4 #&gt; Column: 5 #&gt; Column: 6 #&gt; Column: 7 print(strings_to_correct) #&gt; [1] &quot;BERO\\xe8_SP&quot; &quot;OITHONA_SPINIROSTRIS/ATLANTICA&quot; #&gt; [3] &quot;Autotroph flagellates&quot; &quot;Heterotroph flagellates&quot; #&gt; [5] &quot;Ice algae&quot; &quot;Mixotroph flagellates&quot; #&gt; [7] &quot;Amphipoda/Gammarida&quot; &quot;Amphipoda/Gammaridea&quot; #&gt; [9] &quot;Amphipoda/Hyperiidea&quot; The organisms names are inconsistent and contain ASCII strings, slashes, and spaces that R won’t handle properly. We will replace them. # Store the patterns patterns &lt;- c(&quot;\\xe8&quot;, &quot; &quot;, &quot;/&quot;) # Store their replacements replacements &lt;- c(&quot;E&quot;, &quot;_&quot;, &quot;_&quot;) # Replace the patterns in all columns box::use(box/modify_strings[replace_pattern]) species_list &lt;- replace_pattern(x = species_list, vector_pattern = patterns, vector_replacement = replacements ) #&gt; Replacing &#39;&lt;e8&gt;&#39; with &#39;E&#39; #&gt; Replacing &#39; &#39; with &#39;_&#39; #&gt; Replacing &#39;/&#39; with &#39;_&#39; sp_save &lt;- species_list # species_list &lt;- sp_save Some of the latin name abbreviations are associated with the wrong organism. The abbreviations follow international fisheries standards (e.g. GAD_MOR for ‘GADUS MORHUA’). We can reconstruct the abbreviations from the organisms’ names. # &quot;(^[A-Za-z]{1,3})&quot; # &quot;_+([A-Za-z]{1,3})&quot; abbr1 &lt;- species_list$TROPHOSPECIES %&gt;% str_extract(., &quot;(^[A-Za-z]{1,3})&quot;) abbr2 &lt;- species_list$TROPHOSPECIES %&gt;% str_extract(., &quot;(?&lt;=_)([A-Za-z]{1,3})&quot;) species_list$ABBREVIATION &lt;- paste(abbr1, ifelse(is.na(abbr2), &quot;IND&quot;, abbr2), sep=&quot;_&quot; ) 4.3.1.2 Data augmentation Genus + Species We can extract more information from the ‘trophospecies’ column that contains both the Genus and the species name. We can use the Genus as additional information for the classification. N.B. It does not matter if you do not know what Genus and species names are. Just know that they are deeper levels in the taxonomy of an organism. Genus and species are grouped with ’_’. We can split them. species_list %&lt;&gt;% separate(., col = TROPHOSPECIES, c(&quot;GENUS&quot;, &quot;SPECIES&quot;), remove = FALSE, extra = &quot;drop&quot; ) #&gt; Warning: Expected 2 pieces. Missing pieces filled with `NA` in 6 rows [1, 4, 7, 10, 80, #&gt; 111]. Finally, we can drop the column species because all species are different and cannot be used to group information. # Drop SPECIEs species_list %&lt;&gt;% select(-SPECIES) # Reorganize the species list to follow the taxonomy species_list %&lt;&gt;% relocate(GENUS, .after = FAMILY) 4.4 List of interactions: pairwise list 4.4.1 Data cleaning For the purpose of the analysis, the data in ‘species_list’ and ‘pairwise_list’ need to match. We need to apply the same cleaning to this table. 4.4.1.1 Correct mispellings # debug(locate_pattern) box::use(box/modify_strings[locate_pattern]) box::use(box/modify_strings[replace_pattern]) strings_to_correct &lt;- locate_pattern(pairwise_list, &quot;[^0-9a-zA-Z_-]&quot;) print(strings_to_correct) pairwise_list &lt;- replace_pattern(x = pairwise_list, vector_pattern = patterns, vector_replacement = replacements ) #### Correct PWKEY &quot;(^[A-Za-z]{1,3})&quot; &quot;_+([A-Za-z]{1,3})&quot; # debug(extract_and_merge) extract_and_merge(pairwise_list$PREDATOR, c(&quot;(^[A-Za-z]{1,3})&quot;, &quot;_+([A-Za-z]{1,3})_?&quot;), sep = &quot;&quot; ) box::use(box/modify_strings[test_extract]) test_extract(pairwise_list$PREDATOR, &quot;_+([A-Za-z]{1,3})(?(_)([A-Za-z]{1,3}))&quot;) 4.4.2 Data transformation The data was provided as a long pairwise list which is limiting for the purpose of the analysis. We can convert the list to a squared binary matrix where the intersections of rows and columns contain the information for an interaction. In other words, ‘0s’ means that the interaction is absent (or has yet to be observed in nature); ‘1s’ indicates the presence of an interaction between the organisms listed in the columns and rows interacting. 4.5 "],["data-exploration.html", "Part 5 Data exploration", " Part 5 Data exploration "],["data-analysis.html", "Part 6 Data analysis 6.1 Load dependencies", " Part 6 Data analysis 6.1 Load dependencies "]]
